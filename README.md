# RL PPA Exploration ‚Äî Proof of Concept

This project demonstrates how **reinforcement learning (RL)** can automatically explore trade-offs between **power** and **delay** in circuit design. It uses a **surrogate environment** (simple analytic model) and trains an RL agent (PPO) to learn a **Pareto curve** of optimal trade-offs.  
It‚Äôs organized into clean modules (envs, RL, GUI) and run from a single entrypoint.

---

## üß© What you‚Äôll see when it runs

- A **live stats window** (Tkinter) that shows training metrics (iterations, total timesteps, reward, loss, etc.).
- When training finishes, a **plot window** with the **candidates** and the computed **Pareto front**.
- A timestamped folder under `runs/` with CSV outputs so you can reuse the data.

---

## üóÇÔ∏è Project Structure (overview)

project-root/
‚îú‚îÄ main.py
‚îú‚îÄ config.yaml # All settings go here
‚îú‚îÄ requirements.txt
‚îú‚îÄ envs/
‚îÇ ‚îú‚îÄ init.py
‚îÇ ‚îî‚îÄ surrogate_env.py # SurrogatePPAEnv: toy PPA formulas
‚îú‚îÄ rl/
‚îÇ ‚îú‚îÄ init.py
‚îÇ ‚îú‚îÄ config_loader.py # YAML load + defaults merging
‚îÇ ‚îú‚îÄ env_factory.py # Imports env class from config (safe kwargs)
‚îÇ ‚îú‚îÄ pareto.py # Non-dominated filtering
‚îÇ ‚îî‚îÄ train_worker.py # Training + sweep + CSV outputs
‚îî‚îÄ gui/
‚îú‚îÄ init.py
‚îú‚îÄ live_stats.py # Live training metrics window
‚îî‚îÄ final_plot.py # Final candidates + Pareto plot

yaml
Copy code

---

## üñ•Ô∏è Setup (Windows)

> Assumes you have **Python 3.9+** and **Git** installed. If PowerShell blocks script activation, see step 2b.

### 1) Clone the repository
```powershell
git clone https://github.com/your-org/rl-ppa-demo.git
cd rl-ppa-demo
### 2) Create & activate a virtual environment
powershell
Copy code
python -m venv .venv
.venv\Scripts\Activate.ps1
2b) If activation is blocked (PowerShell policy):

powershell
Copy code
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
.venv\Scripts\Activate.ps1
### 3) Install dependencies
powershell
Copy code
pip install --upgrade pip
pip install -r requirements.txt
If you installed Python via the Microsoft Store and the Tkinter GUI doesn‚Äôt appear, please install the python.org distribution instead. (Tkinter is included there by default.)

### 4) Run
powershell
Copy code
python main.py --config config.yaml
A live stats window opens immediately.

When training completes, a plot window opens (Pareto front).

Outputs go to runs/YYYYMMDD_HHMMSS/.

## Configuration (edit config.yaml)
yaml
Copy code
training:
  policy: "MlpPolicy"
  total_timesteps: 20000   # increase for smoother results
  n_steps: 64
  batch_size: 64
  learning_rate: 0.0003
  gamma: 0.99
  seed: null

env:
  module: "envs.surrogate_env"
  class: "SurrogatePPAEnv"
  params:
    a: 1.0
    b: 1.0
    eps: 0.001
    seed: null

run:
  root: "runs"

log:
  outputs: ["csv"]         # add "stdout" to also print in console
  precreate_progress_row: true
  files:
    progress: "progress.csv"
    candidates: "candidates.csv"
    pareto: "pareto.csv"

sweep:
  points: 61               # how many weights to sample along [0..1]

gui:
  refresh_ms: 500

plot:
  figure_dpi: 120
  figure_size: [6.5, 4.3]

## Outputs
Inside runs/<timestamp>/ you‚Äôll find:

progress.csv ‚Äî training metrics

candidates.csv ‚Äî all evaluated points along the weight sweep

pareto.csv ‚Äî non-dominated subset (Pareto front)

## Troubleshooting
‚ÄúModuleNotFoundError: envs.surrogate_env‚Äù
Make sure you run python main.py from the project root (so relative imports work) and that envs/__init__.py exists.

GUI doesn‚Äôt open
Verify your Python distribution includes Tkinter. The python.org installer does; some variants don‚Äôt.

Unexpected keyword argument ‚Äòa‚Äô (or similar)
Your env.params in config.yaml have keys the env‚Äôs __init__ doesn‚Äôt accept.
Remove those keys or add them to the class signature.

Timesteps end at a different number than requested
PPO processes steps in chunks of n_steps √ó n_envs. It rounds up to the next multiple.
